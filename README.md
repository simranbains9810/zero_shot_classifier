# Zero Shot Classification 0Ô∏è‚É£ü•É
Zero-shot classification refers to the class of machine learning problems where we want our models to predict output for classes which it did not encounter during training time. 

([https://i0.wp.com/masterdai.blog/wp-content/uploads/2024/04/Agentic-Workflow-Explain.png?resize=2048%2C1145&ssl=1](https://user-images.githubusercontent.com/6382701/195600358-24c3f136-96f0-4a8a-8eaf-220970ca0604.png))

The model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes. This method leverages a pre-trained language model BART (Bidirectional and Auto-Regressive Transformers), specifically facebook/bart-large-mnli, which is a neural network model designed for natural language processing (NLP) tasks. 

BART‚Äôs versatility and strength lie in its ability to both predict missing tokens (like a masked language model) and generate sequences (like a traditional autoregressive model), making it particularly useful for tasks that require understanding and generating text.

