# Zero Shot Classification
Zero-shot classification refers to the class of machine learning problems where we want our models to predict output for classes which it did not encounter during training time. The model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes. This method leverages a pre-trained language model BART (Bidirectional and Auto-Regressive Transformers), specifically facebook/bart-large-mnli, which is a neural network model designed for natural language processing (NLP) tasks. BARTâ€™s versatility and strength lie in its ability to both predict missing tokens (like a masked language model) and generate sequences (like a traditional autoregressive model), making it particularly useful for tasks that require understanding and generating text.
